{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"../names.txt\", \"r\").read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\".\"] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "stoi = {c: i for i, c in enumerate(alphabet)}\n",
    "itos = {i: c for i, c in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n",
      "olivia\n",
      "... -----> o\n",
      "..o -----> l\n",
      ".ol -----> i\n",
      "oli -----> v\n",
      "liv -----> i\n",
      "ivi -----> a\n",
      "via -----> .\n",
      "ava\n",
      "... -----> a\n",
      "..a -----> v\n",
      ".av -----> a\n",
      "ava -----> .\n",
      "isabella\n",
      "... -----> i\n",
      "..i -----> s\n",
      ".is -----> a\n",
      "isa -----> b\n",
      "sab -----> e\n",
      "abe -----> l\n",
      "bel -----> l\n",
      "ell -----> a\n",
      "lla -----> .\n",
      "sophia\n",
      "... -----> s\n",
      "..s -----> o\n",
      ".so -----> p\n",
      "sop -----> h\n",
      "oph -----> i\n",
      "phi -----> a\n",
      "hia -----> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # how many chars do we take to predict the next one\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), \"----->\", itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2)) # embedding lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6403,  1.2789])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6403,  1.2789])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6487,  2.0761, -2.1154,  ..., -1.0748,  0.6696, -1.3345],\n",
       "        [ 3.1558,  4.7716, -1.8785,  ..., -3.5373,  3.0511, -1.4601],\n",
       "        [-1.9476,  3.4110, -4.6199,  ..., -0.6041, -3.5416, -4.8619],\n",
       "        ...,\n",
       "        [ 1.6764,  2.6437,  2.7410,  ...,  0.6911,  3.7463,  2.3815],\n",
       "        [-0.7012,  3.4301, -0.2902,  ..., -1.1528,  3.8777,  3.3636],\n",
       "        [-7.5819,  0.1773,  2.0939,  ...,  3.4355,  2.9556,  1.1977]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(-1, 6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.7534)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-prob[torch.arange(32), Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- rewrite and clean up ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # how many chars do we take to predict the next one\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(\"\".join(itos[i] for i in context), \"----->\", itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10 ** lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 1000 = 8.339794158935547\n",
      "loss at step 2000 = 5.773024559020996\n",
      "loss at step 3000 = 4.567688941955566\n",
      "loss at step 4000 = 3.9008214473724365\n",
      "loss at step 5000 = 3.55029559135437\n",
      "loss at step 6000 = 3.3327414989471436\n",
      "loss at step 7000 = 3.188147783279419\n",
      "loss at step 8000 = 3.0832204818725586\n",
      "loss at step 9000 = 3.0049476623535156\n",
      "loss at step 10000 = 2.941922664642334\n"
     ]
    }
   ],
   "source": [
    "# lri = []\n",
    "# lossi = []\n",
    "for i in range(10000):\n",
    "    batch_ixs = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X[batch_ixs]]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = -prob[torch.arange(emb.shape[0]), Y].log().mean()\n",
    "    reg = 0.05 * sum((p ** 2).mean() for p in parameters)\n",
    "    loss = F.cross_entropy(logits, Y[batch_ixs]) + reg\n",
    "    \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        emb = C[X]\n",
    "        h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        overall_loss = F.cross_entropy(logits, Y)\n",
    "        print(f\"loss at step {i+1} = {overall_loss.item()}\")\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # lossi.append(loss.item())\n",
    "    loss.backward()\n",
    "    # lr = lrs[i]\n",
    "    lr = 0.002\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    # lri.append(lr)\n",
    "        \n",
    "# base model had loss of 2.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training split, dev/validation split, test split\n",
    "# train params, train hyperparams, evaluate (should be done infrequently)\n",
    "# 80, 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    random.seed(42)\n",
    "    random.shuffle(words)\n",
    "    \n",
    "    block_size = 3\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    n1 = int(0.8 * len(words))\n",
    "    n2 = int(0.9 * len(words))\n",
    "\n",
    "    Xtr, Ytr = X[:n1], Y[:n1]\n",
    "    Xdev, Ydev = X[n1:n2], Y[n1:n2]\n",
    "    Xte, Yte = X[n2:], Y[n2:]\n",
    "\n",
    "    return Xtr, Ytr, Xdev, Ydev, Xte, Yte\n",
    "\n",
    "Xtr, Ytr, Xdev, Ydev, Xte, Yte = build_dataset(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 300), generator=g)\n",
    "b1 = torch.randn(300, generator=g)\n",
    "W2 = torch.randn((300, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10281"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10 ** lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lri = []\n",
    "# lossi = []\n",
    "# stepi = []\n",
    "\n",
    "for i in range(30000):\n",
    "    batch_ixs = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xtr[batch_ixs]]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # reg = 0.05 * sum((p ** 2).mean() for p in parameters)\n",
    "    loss = F.cross_entropy(logits, Ytr[batch_ixs])\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "    # alpha = 0.175\n",
    "    # gamma = 1\n",
    "    # beta = -np.log(gamma) - 1\n",
    "    # lr = np.exp(-((i + 1) ** alpha + beta))\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # stepi.append(i)\n",
    "    # lri.append(lr)\n",
    "    # lossi.append(loss.item())\n",
    "\n",
    "    # if (i + 1) % 1000 == 0:\n",
    "    #     emb = C[Xtr]\n",
    "    #     h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    #     logits = h @ W2 + b2\n",
    "    #     overall_loss = F.cross_entropy(logits, Ytr)\n",
    "    #     print(f\"tr loss at step {i+1} = {overall_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr loss at step 30000 = 2.464905261993408\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xtr]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "overall_loss = F.cross_entropy(logits, Ytr)\n",
    "print(f\"tr loss at step {i+1} = {overall_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev loss at step 30000 = 2.4854488372802734\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "overall_loss = F.cross_entropy(logits, Ydev)\n",
    "print(f\"dev loss at step {i+1} = {overall_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(C[:, 0].data, C[:, 1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i, 0].item(), C[i, 1].item(), itos[i], ha=\"center\", va=\"center\")\n",
    "plt.grid(\"minor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up to 10d embeddings\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "W1 = torch.randn((30, 200), generator=g)\n",
    "b1 = torch.randn(200, generator=g)\n",
    "W2 = torch.randn((200, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10 ** lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "tr loss at step 1000 = 3.426938533782959\n",
      "dev loss = 3.707991123199463\n",
      "lr = 0.21417267312607005\n",
      "--------------------\n",
      "tr loss at step 2000 = 2.87309193611145\n",
      "dev loss = 3.2002267837524414\n",
      "lr = 0.16692279681244065\n",
      "--------------------\n",
      "tr loss at step 3000 = 2.633845806121826\n",
      "dev loss = 2.9392006397247314\n",
      "lr = 0.14267129234635761\n",
      "--------------------\n",
      "tr loss at step 4000 = 2.4983513355255127\n",
      "dev loss = 2.803725004196167\n",
      "lr = 0.1269547216796825\n",
      "--------------------\n",
      "tr loss at step 5000 = 2.494961738586426\n",
      "dev loss = 2.792266607284546\n",
      "lr = 0.11559900858694484\n",
      "--------------------\n",
      "tr loss at step 6000 = 2.4609804153442383\n",
      "dev loss = 2.757525682449341\n",
      "lr = 0.10685182016761786\n",
      "--------------------\n",
      "tr loss at step 7000 = 2.4817519187927246\n",
      "dev loss = 2.7771127223968506\n",
      "lr = 0.09982199903217022\n",
      "--------------------\n",
      "tr loss at step 8000 = 2.3680572509765625\n",
      "dev loss = 2.642892360687256\n",
      "lr = 0.09399875128192368\n",
      "--------------------\n",
      "tr loss at step 9000 = 2.3484280109405518\n",
      "dev loss = 2.6539580821990967\n",
      "lr = 0.08906410479836022\n",
      "--------------------\n",
      "tr loss at step 10000 = 2.306060791015625\n",
      "dev loss = 2.598674774169922\n",
      "lr = 0.08480773679759514\n",
      "--------------------\n",
      "tr loss at step 11000 = 2.291191577911377\n",
      "dev loss = 2.6067471504211426\n",
      "lr = 0.08108389198616167\n",
      "--------------------\n",
      "tr loss at step 12000 = 2.277656316757202\n",
      "dev loss = 2.5790553092956543\n",
      "lr = 0.07778775595152827\n",
      "--------------------\n",
      "tr loss at step 13000 = 2.2474000453948975\n",
      "dev loss = 2.566818952560425\n",
      "lr = 0.07484165349438816\n",
      "--------------------\n",
      "tr loss at step 14000 = 2.2717947959899902\n",
      "dev loss = 2.5645227432250977\n",
      "lr = 0.07218656613137875\n",
      "--------------------\n",
      "tr loss at step 15000 = 2.2598211765289307\n",
      "dev loss = 2.572970151901245\n",
      "lr = 0.06977669612934174\n",
      "--------------------\n",
      "tr loss at step 16000 = 2.212852716445923\n",
      "dev loss = 2.5331201553344727\n",
      "lr = 0.06757585859244965\n",
      "--------------------\n",
      "tr loss at step 17000 = 2.2320189476013184\n",
      "dev loss = 2.551382541656494\n",
      "lr = 0.06555501431506558\n",
      "--------------------\n",
      "tr loss at step 18000 = 2.202554702758789\n",
      "dev loss = 2.526293992996216\n",
      "lr = 0.06369053875279415\n",
      "--------------------\n",
      "tr loss at step 19000 = 2.2052440643310547\n",
      "dev loss = 2.530470132827759\n",
      "lr = 0.06196297995491983\n",
      "--------------------\n",
      "tr loss at step 20000 = 2.183237314224243\n",
      "dev loss = 2.5031628608703613\n",
      "lr = 0.06035614960821989\n",
      "--------------------\n",
      "tr loss at step 21000 = 2.2276840209960938\n",
      "dev loss = 2.554250717163086\n",
      "lr = 0.05885644613572952\n",
      "--------------------\n",
      "tr loss at step 22000 = 2.1975650787353516\n",
      "dev loss = 2.526818037033081\n",
      "lr = 0.05745234268697393\n",
      "--------------------\n",
      "tr loss at step 23000 = 2.214015007019043\n",
      "dev loss = 2.543034791946411\n",
      "lr = 0.056133994390743513\n",
      "--------------------\n",
      "tr loss at step 24000 = 2.159902334213257\n",
      "dev loss = 2.499938726425171\n",
      "lr = 0.05489293325521601\n",
      "--------------------\n",
      "tr loss at step 25000 = 2.1594173908233643\n",
      "dev loss = 2.4870314598083496\n",
      "lr = 0.05372182841776908\n",
      "--------------------\n",
      "tr loss at step 26000 = 2.1553795337677\n",
      "dev loss = 2.4927680492401123\n",
      "lr = 0.05261429576330475\n",
      "--------------------\n",
      "tr loss at step 27000 = 2.1617298126220703\n",
      "dev loss = 2.4767661094665527\n",
      "lr = 0.051564745288011256\n",
      "--------------------\n",
      "tr loss at step 28000 = 2.1476032733917236\n",
      "dev loss = 2.486891508102417\n",
      "lr = 0.05056825764108792\n",
      "--------------------\n",
      "tr loss at step 29000 = 2.1539664268493652\n",
      "dev loss = 2.492262363433838\n",
      "lr = 0.04962048345107984\n",
      "--------------------\n",
      "tr loss at step 30000 = 2.172489881515503\n",
      "dev loss = 2.523721694946289\n",
      "lr = 0.04871756061146952\n",
      "--------------------\n",
      "tr loss at step 31000 = 2.161165714263916\n",
      "dev loss = 2.506678342819214\n",
      "lr = 0.04785604584522639\n",
      "--------------------\n",
      "tr loss at step 32000 = 2.1462080478668213\n",
      "dev loss = 2.4788312911987305\n",
      "lr = 0.04703285771392396\n",
      "--------------------\n",
      "tr loss at step 33000 = 2.1443030834198\n",
      "dev loss = 2.494152784347534\n",
      "lr = 0.046245228868682875\n",
      "--------------------\n",
      "tr loss at step 34000 = 2.1336686611175537\n",
      "dev loss = 2.4720773696899414\n",
      "lr = 0.04549066581658872\n",
      "--------------------\n",
      "tr loss at step 35000 = 2.126424789428711\n",
      "dev loss = 2.4845733642578125\n",
      "lr = 0.04476691483888968\n",
      "--------------------\n",
      "tr loss at step 36000 = 2.1159517765045166\n",
      "dev loss = 2.4637603759765625\n",
      "lr = 0.04407193297577026\n",
      "--------------------\n",
      "tr loss at step 37000 = 2.116590976715088\n",
      "dev loss = 2.471007823944092\n",
      "lr = 0.043403863208108386\n",
      "--------------------\n",
      "tr loss at step 38000 = 2.1270482540130615\n",
      "dev loss = 2.474231243133545\n",
      "lr = 0.04276101313484154\n",
      "--------------------\n",
      "tr loss at step 39000 = 2.1232709884643555\n",
      "dev loss = 2.4765465259552\n",
      "lr = 0.04214183657675691\n",
      "--------------------\n",
      "tr loss at step 40000 = 2.104250431060791\n",
      "dev loss = 2.451456308364868\n",
      "lr = 0.04154491764211115\n",
      "--------------------\n",
      "tr loss at step 41000 = 2.1165566444396973\n",
      "dev loss = 2.4736547470092773\n",
      "lr = 0.04096895687277205\n",
      "--------------------\n",
      "tr loss at step 42000 = 2.0992000102996826\n",
      "dev loss = 2.4641265869140625\n",
      "lr = 0.04041275915629969\n",
      "--------------------\n",
      "tr loss at step 43000 = 2.1000423431396484\n",
      "dev loss = 2.4496452808380127\n",
      "lr = 0.039875223143155336\n",
      "--------------------\n",
      "tr loss at step 44000 = 2.107300043106079\n",
      "dev loss = 2.4533138275146484\n",
      "lr = 0.03935533195179015\n",
      "--------------------\n",
      "tr loss at step 45000 = 2.107738971710205\n",
      "dev loss = 2.474011182785034\n",
      "lr = 0.0388521449798469\n",
      "--------------------\n",
      "tr loss at step 46000 = 2.0929269790649414\n",
      "dev loss = 2.4522125720977783\n",
      "lr = 0.038364790668751106\n",
      "--------------------\n",
      "tr loss at step 47000 = 2.0881447792053223\n",
      "dev loss = 2.438603401184082\n",
      "lr = 0.03789246009284751\n",
      "--------------------\n",
      "tr loss at step 48000 = 2.0869030952453613\n",
      "dev loss = 2.453585386276245\n",
      "lr = 0.03743440126396894\n",
      "--------------------\n",
      "tr loss at step 49000 = 2.1048147678375244\n",
      "dev loss = 2.4637882709503174\n",
      "lr = 0.0369899140586884\n",
      "--------------------\n",
      "tr loss at step 50000 = 2.1095104217529297\n",
      "dev loss = 2.4637880325317383\n",
      "lr = 0.0365583456891419\n",
      "--------------------\n",
      "tr loss at step 51000 = 2.090604305267334\n",
      "dev loss = 2.461604595184326\n",
      "lr = 0.03613908664970889\n",
      "--------------------\n",
      "tr loss at step 52000 = 2.1053967475891113\n",
      "dev loss = 2.4733448028564453\n",
      "lr = 0.03573156708141002\n",
      "--------------------\n",
      "tr loss at step 53000 = 2.084289073944092\n",
      "dev loss = 2.455078125\n",
      "lr = 0.03533525350394519\n",
      "--------------------\n",
      "tr loss at step 54000 = 2.0800044536590576\n",
      "dev loss = 2.452664852142334\n",
      "lr = 0.03494964587211076\n",
      "--------------------\n",
      "tr loss at step 55000 = 2.0860612392425537\n",
      "dev loss = 2.4505581855773926\n",
      "lr = 0.03457427491911812\n",
      "--------------------\n",
      "tr loss at step 56000 = 2.077176809310913\n",
      "dev loss = 2.4420297145843506\n",
      "lr = 0.03420869975425435\n",
      "--------------------\n",
      "tr loss at step 57000 = 2.0968124866485596\n",
      "dev loss = 2.4691593647003174\n",
      "lr = 0.033852505686526285\n",
      "--------------------\n",
      "tr loss at step 58000 = 2.080397844314575\n",
      "dev loss = 2.461740255355835\n",
      "lr = 0.03350530224952296\n",
      "--------------------\n",
      "tr loss at step 59000 = 2.070617437362671\n",
      "dev loss = 2.4445855617523193\n",
      "lr = 0.03316672140581786\n",
      "--------------------\n",
      "tr loss at step 60000 = 2.062837839126587\n",
      "dev loss = 2.4392571449279785\n",
      "lr = 0.0328364159118894\n",
      "--------------------\n",
      "tr loss at step 61000 = 2.0692031383514404\n",
      "dev loss = 2.4487526416778564\n",
      "lr = 0.032514057826829666\n",
      "--------------------\n",
      "tr loss at step 62000 = 2.079799175262451\n",
      "dev loss = 2.4466021060943604\n",
      "lr = 0.03219933715009723\n",
      "--------------------\n",
      "tr loss at step 63000 = 2.076449394226074\n",
      "dev loss = 2.4529359340667725\n",
      "lr = 0.03189196057528946\n",
      "--------------------\n",
      "tr loss at step 64000 = 2.0666630268096924\n",
      "dev loss = 2.4490511417388916\n",
      "lr = 0.0315916503484073\n",
      "--------------------\n",
      "tr loss at step 65000 = 2.0635578632354736\n",
      "dev loss = 2.446624994277954\n",
      "lr = 0.03129814322038889\n",
      "--------------------\n",
      "tr loss at step 66000 = 2.0731256008148193\n",
      "dev loss = 2.4565443992614746\n",
      "lr = 0.03101118948482869\n",
      "--------------------\n",
      "tr loss at step 67000 = 2.06530499458313\n",
      "dev loss = 2.4551758766174316\n",
      "lr = 0.030730552092794704\n",
      "--------------------\n",
      "tr loss at step 68000 = 2.050687074661255\n",
      "dev loss = 2.4306788444519043\n",
      "lr = 0.030456005837532427\n",
      "--------------------\n",
      "tr loss at step 69000 = 2.0868213176727295\n",
      "dev loss = 2.466517210006714\n",
      "lr = 0.03018733660261177\n",
      "--------------------\n",
      "tr loss at step 70000 = 2.0555765628814697\n",
      "dev loss = 2.4342153072357178\n",
      "lr = 0.029924340667751632\n",
      "--------------------\n",
      "tr loss at step 71000 = 2.075042247772217\n",
      "dev loss = 2.4598562717437744\n",
      "lr = 0.0296668240671527\n",
      "--------------------\n",
      "tr loss at step 72000 = 2.051044225692749\n",
      "dev loss = 2.451063871383667\n",
      "lr = 0.029414601995698897\n",
      "--------------------\n",
      "tr loss at step 73000 = 2.0601181983947754\n",
      "dev loss = 2.4561705589294434\n",
      "lr = 0.029167498258854185\n",
      "--------------------\n",
      "tr loss at step 74000 = 2.0533881187438965\n",
      "dev loss = 2.4428796768188477\n",
      "lr = 0.028925344762496953\n",
      "--------------------\n",
      "tr loss at step 75000 = 2.0554349422454834\n",
      "dev loss = 2.4334168434143066\n",
      "lr = 0.028687981039303184\n",
      "--------------------\n",
      "tr loss at step 76000 = 2.0509140491485596\n",
      "dev loss = 2.4541244506835938\n",
      "lr = 0.028455253808617104\n",
      "--------------------\n",
      "tr loss at step 77000 = 2.0546374320983887\n",
      "dev loss = 2.447009325027466\n",
      "lr = 0.028227016567040943\n",
      "--------------------\n",
      "tr loss at step 78000 = 2.0467209815979004\n",
      "dev loss = 2.441188097000122\n",
      "lr = 0.02800312920723684\n",
      "--------------------\n",
      "tr loss at step 79000 = 2.037843704223633\n",
      "dev loss = 2.4349122047424316\n",
      "lr = 0.027783457662666943\n",
      "--------------------\n",
      "tr loss at step 80000 = 2.0425937175750732\n",
      "dev loss = 2.4347786903381348\n",
      "lr = 0.027567873576207467\n",
      "--------------------\n",
      "tr loss at step 81000 = 2.0420081615448\n",
      "dev loss = 2.4426941871643066\n",
      "lr = 0.027356253990760075\n",
      "--------------------\n",
      "tr loss at step 82000 = 2.0476295948028564\n",
      "dev loss = 2.4398131370544434\n",
      "lr = 0.0271484810601517\n",
      "--------------------\n",
      "tr loss at step 83000 = 2.0449039936065674\n",
      "dev loss = 2.446836471557617\n",
      "lr = 0.02694444177876685\n",
      "--------------------\n",
      "tr loss at step 84000 = 2.041102647781372\n",
      "dev loss = 2.4340980052948\n",
      "lr = 0.02674402772849101\n",
      "--------------------\n",
      "tr loss at step 85000 = 2.06284761428833\n",
      "dev loss = 2.4562506675720215\n",
      "lr = 0.02654713484166904\n",
      "--------------------\n",
      "tr loss at step 86000 = 2.0298357009887695\n",
      "dev loss = 2.4225149154663086\n",
      "lr = 0.026353663178891075\n",
      "--------------------\n",
      "tr loss at step 87000 = 2.03796124458313\n",
      "dev loss = 2.436016321182251\n",
      "lr = 0.026163516720521144\n",
      "--------------------\n",
      "tr loss at step 88000 = 2.04728627204895\n",
      "dev loss = 2.4475603103637695\n",
      "lr = 0.025976603170972945\n",
      "--------------------\n",
      "tr loss at step 89000 = 2.0254180431365967\n",
      "dev loss = 2.4321064949035645\n",
      "lr = 0.025792833774820313\n",
      "--------------------\n",
      "tr loss at step 90000 = 2.0312561988830566\n",
      "dev loss = 2.4326372146606445\n",
      "lr = 0.025612123143904448\n",
      "--------------------\n",
      "tr loss at step 91000 = 2.0481271743774414\n",
      "dev loss = 2.4475367069244385\n",
      "lr = 0.02543438909466771\n",
      "--------------------\n",
      "tr loss at step 92000 = 2.035773515701294\n",
      "dev loss = 2.441270351409912\n",
      "lr = 0.02525955249500577\n",
      "--------------------\n",
      "tr loss at step 93000 = 2.037405014038086\n",
      "dev loss = 2.433649778366089\n",
      "lr = 0.02508753711998526\n",
      "--------------------\n",
      "tr loss at step 94000 = 2.026717185974121\n",
      "dev loss = 2.4191782474517822\n",
      "lr = 0.02491826951582638\n",
      "--------------------\n",
      "tr loss at step 95000 = 2.028857469558716\n",
      "dev loss = 2.431813955307007\n",
      "lr = 0.024751678871595132\n",
      "--------------------\n",
      "tr loss at step 96000 = 2.0263752937316895\n",
      "dev loss = 2.4226222038269043\n",
      "lr = 0.024587696898093852\n",
      "--------------------\n",
      "tr loss at step 97000 = 2.028287410736084\n",
      "dev loss = 2.43115496635437\n",
      "lr = 0.024426257713476396\n",
      "--------------------\n",
      "tr loss at step 98000 = 2.026130199432373\n",
      "dev loss = 2.4333317279815674\n",
      "lr = 0.024267297735150652\n",
      "--------------------\n",
      "tr loss at step 99000 = 2.021207571029663\n",
      "dev loss = 2.424661159515381\n",
      "lr = 0.024110755577563356\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb#X65sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m lr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m((i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m alpha \u001b[39m+\u001b[39m beta))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb#X65sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb#X65sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     p\u001b[39m.\u001b[39mdata \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m p\u001b[39m.\u001b[39mgrad\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb#X65sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m stepi\u001b[39m.\u001b[39mappend(i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/benjamin/Documents/Code/andrej-karpathy-ml/makemore/bigram_mlp.ipynb#X65sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# lri.append(lr)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(200000):\n",
    "    batch_ixs = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xtr[batch_ixs]]\n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    reg = 0.05 * sum((p ** 2).mean() for p in parameters)\n",
    "    loss = F.cross_entropy(logits, Ytr[batch_ixs]) + reg\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "    alpha = 0.135\n",
    "    gamma = 1\n",
    "    beta = -np.log(gamma) - 1\n",
    "    lr = np.exp(-((i + 1) ** alpha + beta))\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    stepi.append(i)\n",
    "    # lri.append(lr)\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(\"--------------------\")\n",
    "        emb = C[Xtr]\n",
    "        h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        overall_loss = F.cross_entropy(logits, Ytr)\n",
    "        print(f\"tr loss at step {i+1} = {overall_loss.item()}\")\n",
    "        emb = C[Xdev]\n",
    "        h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        overall_loss = F.cross_entropy(logits, Ydev)\n",
    "        print(f\"dev loss = {overall_loss.item()}\")\n",
    "        print(f\"lr = {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3fb08b7970>]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9813, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "overall_loss = F.cross_entropy(logits, Ytr)\n",
    "overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4146, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "overall_loss = F.cross_entropy(logits, Ydev)\n",
    "overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmahzaan.\n",
      "hari.\n",
      "kimberretty.\n",
      "salayan.\n",
      "jazonte.\n",
      "amerync.\n",
      "kaqhilor.\n",
      "mari.\n",
      "chaiir.\n",
      "kaleigh.\n",
      "ham.\n",
      "jois.\n",
      "quston.\n",
      "rove.\n",
      "alianni.\n",
      "wazeron.\n",
      "jaryn.\n",
      "kakhengiylan.\n",
      "emderica.\n",
      "gianahya.\n",
      "kaylaad.\n",
      "bulah.\n",
      "sya.\n",
      "smalon.\n",
      "zeryxonni.\n",
      "alairo.\n",
      "nee.\n",
      "kaadin.\n",
      "oceanner.\n",
      "oza.\n",
      "krynce.\n",
      "mollianna.\n",
      "seden.\n",
      "loqhaib.\n",
      "bren.\n",
      "adyn.\n",
      "tituso.\n",
      "collietpranis.\n",
      "qukorce.\n",
      "zazingtyn.\n",
      "khengel.\n",
      "antezamilenn.\n",
      "kyperylon.\n",
      "rour.\n",
      "konston.\n",
      "kirockoleiler.\n",
      "shan.\n",
      "elanini.\n",
      "eronel.\n",
      "kyroseyah.\n",
      "keliah.\n",
      "mawryston.\n",
      "hani.\n",
      "kayleyah.\n",
      "cah.\n",
      "kolani.\n",
      "ari.\n",
      "kaal.\n",
      "mav.\n",
      "kento.\n",
      "itza.\n",
      "ryn.\n",
      "kel.\n",
      "catiylandelah.\n",
      "jouleen.\n",
      "dhandara.\n",
      "dakhakeer.\n",
      "tan.\n",
      "aviana.\n",
      "jmanah.\n",
      "theley.\n",
      "wayar.\n",
      "ledyn.\n",
      "vheopmy.\n",
      "mari.\n",
      "maria.\n",
      "mavyonoraiyel.\n",
      "abyana.\n",
      "kimberliseynasvia.\n",
      "moline.\n",
      "talenostefa.\n",
      "kemon.\n",
      "jaei.\n",
      "emya.\n",
      "kenne.\n",
      "natytura.\n",
      "caxleon.\n",
      "cendesabelw.\n",
      "evrixah.\n",
      "zeniusayealudrakian.\n",
      "abrithiannaedeassi.\n",
      "emmadious.\n",
      "biwhanned.\n",
      "teanne.\n",
      "kzon.\n",
      "keidhahayia.\n",
      "kayj.\n",
      "shaythais.\n",
      "lote.\n",
      "atdlynnamiana.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(100):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(\"\".join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a15702a29ea01ae7aa6b51d803dd08c0ac5dbedc153ed7a5fc67a3e004dd827d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
