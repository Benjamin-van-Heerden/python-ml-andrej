{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w.strip() for w in open(\"../names.txt\").readlines()]\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\".\"] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "stoi = {c: i for i, c in enumerate(alphabet)}\n",
    "itos = {i: c for i, c in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set of all the bigrams (x, y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        i1 = stoi[c1]\n",
    "        i2 = stoi[c2]\n",
    "        xs.append(i1)\n",
    "        ys.append(i2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the inputs\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f058dd76e20>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAABdCAYAAACM0CxCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGsklEQVR4nO3dT4hdZxnH8e/PcVpJ20Vrq7RJNFW6KS5SGbqJSClo/yhGF0oDSruKCwspCFrd2I0goqUbEaINVKwWoVWDFGLRFnUT88eQNh0aQ4k2JiTVLtoKNrZ9XNwbHNM7mTs459y3934/EObOuWfmPE/ey2/eeeecc1NVSJLa9Y5JFyBJujCDWpIaZ1BLUuMMaklqnEEtSY0zqCWpce/s4pteecVcbdo4P/b+Rw+v66IMSXrb+Bf/5Gy9llHPdRLUmzbO88c9G8fe/5ZrNndRhiS9beyt3yz73FhLH0luTfJckmNJ7l2zyiRJK1oxqJPMAd8DbgOuB7Ylub7rwiRJA+PMqG8EjlXV81V1FngE2NptWZKkc8YJ6vXAC0s+PzHcJknqwThBPeqvkG+5k1OS7Un2J9n/4j/e+P8rkyQB4wX1CWDpKRwbgJPn71RVO6tqoaoWrnr33FrVJ0kzb5yg3gdcl+TaJBcBdwC7uy1LknTOiudRV9XrSe4G9gBzwK6qOtJ5ZZIkYMwLXqrqceDxjmuRJI3gvT4kqXGdXEJ+9PC6mbwsfM/JQ6vafxb/jyStnjNqSWqcQS1JjTOoJalxBrUkNc6glqTGGdSS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDWuk5syzSpvstSO1d4gCxw/tcsZtSQ1bsWgTrIxyZNJFpMcSbKjj8IkSQPjLH28Dny5qg4muQw4kOSJqnq249okSYwxo66qU1V1cPj4FWARWN91YZKkgVWtUSfZBNwA7O2kGknSW4x91keSS4FHgXuq6uURz28HtgO8i3VrVqAkzbqxZtRJ5hmE9MNV9diofapqZ1UtVNXCPBevZY2SNNPGOesjwIPAYlXd331JkqSlxplRbwG+ANyc5NDw3+0d1yVJGlpxjbqq/gCkh1okSSN4ZaIkNc6glqTGGdSS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJatzYb8XVpT0nD636a265ZvOa16Hp4etD08QZtSQ1buygTjKX5E9JftVlQZKk/7WaGfUOYLGrQiRJo437LuQbgE8AP+y2HEnS+cadUT8AfAV4s7tSJEmjrBjUST4JnKmqAyvstz3J/iT7/81ra1agJM26cWbUW4BPJTkOPALcnOTH5+9UVTuraqGqFua5eI3LlKTZtWJQV9XXqmpDVW0C7gB+W1Wf77wySRLgedSS1LxVXZlYVU8BT3VSiSRpJGfUktS4VNXaf9PkReAvI566Evj7mh+wffY9W+x7tqxV3++vqqtGPdFJUC8nyf6qWujtgI2w79li37Olj75d+pCkxhnUktS4voN6Z8/Ha4V9zxb7ni2d993rGrUkafVc+pCkxvUS1EluTfJckmNJ7u3jmC1IcjzJ00kOJdk/6Xq6lGRXkjNJnlmy7YokTyT58/Dj5ZOssQvL9H1fkr8Nx/1QktsnWeNaS7IxyZNJFpMcSbJjuH2qx/sCfXc+3p0vfSSZA44CHwNOAPuAbVX1bKcHbsDwRlYLVTX155Ym+SjwKvCjqvrQcNu3gZeq6lvDH9CXV9VXJ1nnWlum7/uAV6vqO5OsrStJrgaurqqDSS4DDgCfBu5iisf7An1/jo7Hu48Z9Y3Asap6vqrOMrgD39YejqseVdXvgJfO27wVeGj4+CEGL+qpskzfU62qTlXVweHjVxi889N6pny8L9B35/oI6vXAC0s+P0FPzTWggF8nOZBk+6SLmYD3VtUpGLzIgfdMuJ4+3Z3k8HBpZKqWAJZKsgm4AdjLDI33eX1Dx+PdR1BnxLZZOdVkS1V9GLgN+NLw12RNv+8DHwQ2A6eA7060mo4kuRR4FLinql6edD19GdF35+PdR1CfADYu+XwDcLKH405cVZ0cfjwD/JzBMtAsOT1c1zu3vndmwvX0oqpOV9UbVfUm8AOmcNyTzDMIq4er6rHh5qkf71F99zHefQT1PuC6JNcmuYjBmw/s7uG4E5XkkuEfHEhyCfBx4JkLf9XU2Q3cOXx8J/DLCdbSm3NhNfQZpmzckwR4EFisqvuXPDXV471c332Mdy8XvAxPV3kAmAN2VdU3Oz/ohCX5AINZNAzu+/2Tae47yU+BmxjcSew08A3gF8DPgPcBfwU+W1VT9Ye3Zfq+icGvwQUcB754bu12GiT5CPB74Gn++4bXX2ewXju1432BvrfR8Xh7ZaIkNc4rEyWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJapxBLUmN+w9AXCCNBMImrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674e+00, -2.3729e-01, -2.7385e-02, -1.1008e+00,  2.8588e-01,\n",
       "         -2.9643e-02, -1.5471e+00,  6.0489e-01,  7.9136e-02,  9.0462e-01,\n",
       "         -4.7125e-01,  7.8682e-01, -3.2843e-01, -4.3297e-01,  1.3729e+00,\n",
       "          2.9334e+00,  1.5618e+00, -1.6261e+00,  6.7716e-01, -8.4039e-01,\n",
       "          9.8488e-01, -1.4837e-01, -1.4795e+00,  4.4830e-01, -7.0730e-02,\n",
       "          2.4968e+00,  2.4448e+00],\n",
       "        [ 4.7236e-01,  1.4830e+00,  3.1748e-01,  1.0588e+00,  2.3982e+00,\n",
       "          4.6827e-01, -6.5650e-01,  6.1662e-01, -6.2197e-01,  5.1007e-01,\n",
       "          1.3563e+00,  2.3445e-01, -4.5585e-01, -1.3132e-03, -5.1161e-01,\n",
       "          5.5570e-01,  4.7458e-01, -1.3867e+00,  1.6229e+00,  1.7197e-01,\n",
       "          9.8846e-01,  5.0657e-01,  1.0198e+00, -1.9062e+00, -4.2753e-01,\n",
       "         -2.1259e+00,  9.6041e-01],\n",
       "        [ 1.9359e-01,  1.0532e+00,  6.3393e-01,  2.5786e-01,  9.6408e-01,\n",
       "         -2.4855e-01,  2.4756e-02, -3.0404e-02,  1.5622e+00, -4.4852e-01,\n",
       "         -1.2345e+00,  1.1220e+00, -6.7381e-01,  3.7882e-02, -5.5881e-01,\n",
       "         -8.2709e-01,  8.2253e-01, -7.5100e-01,  9.2778e-01, -1.4849e+00,\n",
       "         -2.1293e-01, -1.1860e+00, -6.6092e-01, -2.3348e-01,  1.5447e+00,\n",
       "          6.0061e-01, -7.0909e-01],\n",
       "        [ 1.9359e-01,  1.0532e+00,  6.3393e-01,  2.5786e-01,  9.6408e-01,\n",
       "         -2.4855e-01,  2.4756e-02, -3.0404e-02,  1.5622e+00, -4.4852e-01,\n",
       "         -1.2345e+00,  1.1220e+00, -6.7381e-01,  3.7882e-02, -5.5881e-01,\n",
       "         -8.2709e-01,  8.2253e-01, -7.5100e-01,  9.2778e-01, -1.4849e+00,\n",
       "         -2.1293e-01, -1.1860e+00, -6.6092e-01, -2.3348e-01,  1.5447e+00,\n",
       "          6.0061e-01, -7.0909e-01],\n",
       "        [-6.7006e-01, -1.2199e+00,  3.0314e-01, -1.0725e+00,  7.2762e-01,\n",
       "          5.1114e-02,  1.3095e+00, -8.0220e-01, -8.5042e-01, -1.8068e+00,\n",
       "          1.2523e+00, -1.2256e+00,  1.2165e+00, -9.6478e-01, -2.3211e-01,\n",
       "         -3.4762e-01,  3.3244e-01, -1.3263e+00,  1.1224e+00,  5.9641e-01,\n",
       "          4.5846e-01,  5.4011e-02, -1.7400e+00,  1.1560e-01,  8.0319e-01,\n",
       "          5.4108e-01, -1.1646e+00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
       "         0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
       "         0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459],\n",
       "        [0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
       "         0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
       "         0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472],\n",
       "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
       "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
       "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
       "        [0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
       "         0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
       "         0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
       "        [0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
       "         0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
       "         0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = (xenc @ W)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "bigram example 1: .e (indexes 0, 5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the correct character: 0.01228625513613224\n",
      "log likelihood: -4.399273872375488\n",
      "negative log likelihood: 4.399273872375488\n",
      "---------------\n",
      "bigram example 2: em (indexes 5, 13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the correct character: 0.018050700426101685\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "---------------\n",
      "bigram example 3: mm (indexes 13, 13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "---------------\n",
      "bigram example 4: ma (indexes 13, 1)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the correct character: 0.07367686182260513\n",
      "log likelihood: -2.6080665588378906\n",
      "negative log likelihood: 2.6080665588378906\n",
      "---------------\n",
      "bigram example 5: a. (indexes 1, 0)\n",
      "input to the neural net: 1\n",
      "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
      "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
      "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the correct character: 0.014977526850998402\n",
      "log likelihood: -4.201204299926758\n",
      "negative log likelihood: 4.201204299926758\n",
      "================\n",
      "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(\"---------------\")\n",
    "    print(f\"bigram example {i + 1}: {itos[x]}{itos[y]} (indexes {x}, {y})\")\n",
    "    print(f\"input to the neural net: {x}\")\n",
    "    print(f\"output probabilities from the neural net: {probs[i]}\")\n",
    "    print(f\"label (actual next character): {y}\")\n",
    "    p = probs[i, y]\n",
    "    print(f\"probability assigned by the net to the correct character: {p.item()}\")\n",
    "    logp = torch.log(p)\n",
    "    print(f\"log likelihood: {logp.item()}\")\n",
    "    nll = -logp\n",
    "    print(f\"negative log likelihood: {nll}\")\n",
    "    nlls[i] = nll\n",
    "\n",
    "print(\"================\")\n",
    "print(f\"average negative log likelihood, i.e. loss = {nlls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7693, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(5), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "xenc = F.one_hot(xs, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7693, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True) # this is softmax\n",
    "loss = -probs[torch.arange(5), ys].log().mean() \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero, more efficient than 0\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update params\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.strip() for w in open(\"../names.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\".\"] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "stoi = {c: i for i, c in enumerate(alphabet)}\n",
    "itos = {i: c for i, c in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training set of all the bigrams (x, y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        i1 = stoi[c1]\n",
    "        i2 = stoi[c2]\n",
    "        xs.append(i1)\n",
    "        ys.append(i2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5886809825897217\n",
      "2.522773265838623\n",
      "2.503295660018921\n",
      "2.494736433029175\n",
      "2.4901304244995117\n",
      "2.487379312515259\n",
      "2.485621929168701\n",
      "2.4844377040863037\n",
      "2.4836044311523438\n",
      "2.4829962253570557\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True) # this is softmax\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01 * (W ** 2).mean() # negative log likelihood with regularization\n",
    "    # making the regularization parameter large will yield a more uniform W\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero, more efficient than 0\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # update params\n",
    "    W.data += -50 * W.grad # for this model a very large learning rate seems to work\n",
    "\n",
    "# remember the bigram base model had loss of 2.35\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0580135a60>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(W.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondmaisah.\n",
      "anchshizarie.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        \n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True) # this is softmax\n",
    "\n",
    "\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a15702a29ea01ae7aa6b51d803dd08c0ac5dbedc153ed7a5fc67a3e004dd827d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
